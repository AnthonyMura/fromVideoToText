{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "from pathlib import Path\n",
    "from FileInfo import FileInfo\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import Audio, display"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T18:21:36.982189Z",
     "start_time": "2024-06-14T18:21:36.968315Z"
    }
   },
   "id": "780b8e72185d1682",
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def choose_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T18:21:42.131283Z",
     "start_time": "2024-06-14T18:21:42.128205Z"
    }
   },
   "id": "f515235ab82da065",
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "device = choose_device()\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T18:21:42.588266Z",
     "start_time": "2024-06-14T18:21:42.566158Z"
    }
   },
   "id": "f97c44565d8eabc2",
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "file_p: Path = list(Path(\"audio/\").rglob(\"*mp3\"))[0]\n",
    "file_metadata = torchaudio.info(file_p.as_posix(), format='mp3')\n",
    "str(file_metadata)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T13:23:20.852113Z",
     "start_time": "2024-02-06T13:23:20.664382Z"
    }
   },
   "id": "30ce5b25e75c3a8c",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "waveform, sample_rate = torchaudio.load(file_p.as_posix(), format='mp3')\n",
    "# waveform = waveform[:,:100000]\n",
    "waveform.shape, sample_rate"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T13:23:21.639764Z",
     "start_time": "2024-02-06T13:23:21.628318Z"
    }
   },
   "id": "f6a86854133c6d92",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "torchaudio.save(\"audio/test.wav\", waveform, 16000)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T13:23:51.828208Z",
     "start_time": "2024-02-06T13:23:51.820101Z"
    }
   },
   "id": "5fc8420f798d0372",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "file_p: Path = Path(\"audio/test.wav\")\n",
    "waveform, sample_rate = torchaudio.load(file_p.as_posix(), format='wav')\n",
    "file_metadata = torchaudio.info(file_p.as_posix(), format='wav')\n",
    "str(file_metadata)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T13:25:28.677065Z",
     "start_time": "2024-02-06T13:25:28.629342Z"
    }
   },
   "id": "410de70b32060566",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def play_audio(waveform, sample_rate):\n",
    "    waveform = waveform.numpy()\n",
    "    if waveform.ndim == 2:\n",
    "        display(Audio((waveform[0], waveform[1]), rate=sample_rate))\n",
    "    elif waveform.ndim == 1:\n",
    "        display(Audio(waveform, rate=sample_rate))\n",
    "    else:\n",
    "        raise ValueError(\"Waveform must be 1 or 2 dimensional\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T13:08:09.326470Z",
     "start_time": "2024-02-06T13:08:09.321451Z"
    }
   },
   "id": "a9fa1796a5499ea9",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "play_audio(waveform, sample_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T11:25:26.190403Z",
     "start_time": "2024-02-06T11:25:26.158748Z"
    }
   },
   "id": "8ddebc5203c87c9e",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def _plot(waveform, sample_rate, title):\n",
    "    waveform = waveform.numpy()\n",
    "    num_channels, num_frames = waveform.shape\n",
    "    time_axis = torch.linspace(0, num_frames / sample_rate, num_frames)\n",
    "    \n",
    "    figure, axes = plt.subplots(num_channels, 1)\n",
    "    if num_channels == 1:\n",
    "        axes = [axes]\n",
    "    for c in range(num_channels):\n",
    "        if title == \"Waveform\":\n",
    "            axes[c].plot(time_axis, waveform[c], linewidth=1)\n",
    "            axes[c].grid(True)\n",
    "        else:\n",
    "            axes[c].specgram(waveform[c], Fs=sample_rate)\n",
    "        if num_channels > 1:\n",
    "            axes[c].set_ylabel(f\"Channel {c+1}\")\n",
    "    figure.suptitle(title)\n",
    "    plt.show(block=False)\n",
    "    \n",
    "def plot_waveform(waveform, sample_rate):\n",
    "    _plot(waveform, sample_rate, \"Waveform\")\n",
    "    \n",
    "def plot_specgram(waveform, sample_rate):\n",
    "    _plot(waveform, sample_rate, \"Spectrogram\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T13:08:11.565129Z",
     "start_time": "2024-02-06T13:08:11.561623Z"
    }
   },
   "id": "a930fa838ef34fb5",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "plot_specgram(waveform, sample_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T13:08:11.982084Z",
     "start_time": "2024-02-06T13:08:11.730423Z"
    }
   },
   "id": "5fc0f7483bf2e1b6",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "plot_waveform(waveform, sample_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T13:08:13.174224Z",
     "start_time": "2024-02-06T13:08:12.286049Z"
    }
   },
   "id": "f989b6b5349143fa",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T13:08:13.882696Z",
     "start_time": "2024-02-06T13:08:13.875133Z"
    }
   },
   "id": "c4078648ea937725",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T13:08:14.796101Z",
     "start_time": "2024-02-06T13:08:14.790482Z"
    }
   },
   "id": "deb6b97a452c0137",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "import torch\n",
    "import zipfile\n",
    "import torchaudio\n",
    "from glob import glob\n",
    "\n",
    "device = torch.device('cpu')  # gpu also works, but our models are fast enough for CPU\n",
    "model, decoder, utils = torch.hub.load(repo_or_dir='snakers4/silero-models',\n",
    "                                       model='silero_stt',\n",
    "                                       language='en', # also available 'de', 'es'\n",
    "                                       device=device)\n",
    "(read_batch, split_into_batches,\n",
    " read_audio, prepare_model_input) = utils  # see function signature for details\n",
    "\n",
    "# download a single file in any format compatible with TorchAudio\n",
    "test_files = list(Path.cwd().rglob(\"*.wav\"))\n",
    "batches = split_into_batches(test_files, batch_size=10)\n",
    "input = prepare_model_input(read_batch(batches[0]), device=device)\n",
    "\n",
    "output = model(input)\n",
    "for example in output:\n",
    "    print(decoder(example.cpu()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T14:02:31.475403Z",
     "start_time": "2024-02-06T14:02:10.618803Z"
    }
   },
   "id": "ba5e74b75a00e4d",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "70d730d21c09d2c8",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c691a8c22652a0c2",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "!pip install --upgrade git+https://github.com/huggingface/transformers.git accelerate datasets[audio]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T14:15:15.471404Z",
     "start_time": "2024-02-11T14:15:15.266584Z"
    }
   },
   "id": "bdf487ba61d0a949",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "\n",
    "\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "model_id = \"openai/whisper-large-v3\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    max_new_tokens=128,\n",
    "    chunk_length_s=30,\n",
    "    batch_size=16,\n",
    "    return_timestamps=True,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T14:24:48.528978Z",
     "start_time": "2024-02-11T14:19:38.195860Z"
    }
   },
   "id": "61a874b2b4643fb2",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sample = \"/Users/minkota/Documents/code/Projects/fromVideoToText/audio/test.wav\"\n",
    "\n",
    "result = pipe(sample)\n",
    "print(result[\"text\"])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-11T14:25:12.269992Z"
    }
   },
   "id": "fb9fb28a3ceaa7de",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f5ff71d376b40ce0",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a488f25aa7466e5b",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
